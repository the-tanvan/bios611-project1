```{r include=FALSE}
library(gbm)
library(tidyverse)
library(Caret)
```
# Q1

Repeat your GBM model. Contrast your results with the results for the previous exercise.

With the gbm modeling below, it was found that this model with an accuracy of 91.8% is more accurate than the previous model with an accuracy of 49.8%.

```{r}
q1 = read.csv("/home/rstudio/hw5/q1.csv")
q1.analysis=q1%>%mutate(Male=(Gender=="Male"))
set.seed(392)
q1.train=sample(c(TRUE,FALSE),nrow(q1.analysis),rep=TRUE)
q1.test=(!q1.train)
q1.train = q1.analysis[q1.train,]
q1.test = q1.analysis[q1.test,]
gbm_model <- gbm(formula = Male ~ Weight+Height, 
                    distribution = "bernoulli", 
                    data = q1.train,
                    n.trees = 1000)
gbm_predict = (predict(gbm_model, newdata=q1.test, n.trees=1000,type="response")>0.5)
gbm_results=as.data.frame(cbind(Truth=q1.test$Male,Prediction=gbm_predict)) %>% mutate(correct=(Truth==Prediction))
table(gbm_results$correct)
4585/(4585+408)
```

# Q2
1.  Examine the dataset for any irregularities. Make the case for filtering out a subset of rows (or for not doing so).
2.  Perform a principal component analysis on the numerical columns of this data. How many components do we need to get 85% of the variation in the data set?
3.  Do we need to normalize these columns or not?
4.  Is the "total" column really the total of the values in the other columns?
5.  Should we have included in in the PCA? What do you expect about the largest principal components and the total column? Remember, a given principal component corresponds to a weighted combination of the original variables.
6.  Make a plot of the two largest components. Any insights?

```{r}
q2 = read.csv("/home/rstudio/hw5/q2.csv")
head(q2)

table(q2$Alignment)
ggplot(data=q2, aes(x=Intelligence)) + geom_histogram(bins=10)
ggplot(data=q2, aes(x=Strength)) + geom_histogram(bins=10)
ggplot(data=q2, aes(x=Durability)) + geom_histogram(bins=20)
ggplot(data=q2, aes(x=Power)) + geom_histogram(bins=20)
ggplot(data=q2, aes(x=Combat)) + geom_histogram(bins=20)
ggplot(data=q2, aes(x=Total)) + geom_histogram(bins=20)

temp=q2%>%filter(Total==0)
table(q2$Total)
head(q2%>%filter(Total==5))
```

# Q3

Use Python/sklearn to perform a TSNE dimensionality reduction.

See hw5.ipynb for the TSNE dimensionality reduction.

In R, plot the results. Color each point by the alignment of the associated character. Any insights?

```{r}

```

# Q4

See hw5.ipynb.

# Q5

Using the Caret library, train a GBM model which attempts to predict character alignment. What are the final parameters that caret determines are best for the model.

Hints: you want to use the "train" method with the "gbm" method. Use "repeatedcv" for the characterization method. If this is confusing, don't forget to read the Caret docs.

```{r}

```

# Q6

A conceptual question: why do we need to characterize our models using strategies like k-fold cross validation? Why can't we just report a single number for the accuracy of our model?

To determine the accuracy of a model, we need to use our data to train and test it. If we do a simple split of train and testing data, we may split our data in a way that is biased and leads to a poor model. By using a strategy like k-fold cross validation, we train our model on multiple randomly selected samples from our data, reducing biased and allowing us to have a better estimate of the accuracy of our model.

# Q7

Describe in words the process of recursive feature elimination. 

Recursive feature elimination is a way to select the best predictors for a model. It begins by creating a model with all of the predictors available and then removing the least important predictors. This process is repeated over and over again until the process reaches a stopping point indicated by the analyst.